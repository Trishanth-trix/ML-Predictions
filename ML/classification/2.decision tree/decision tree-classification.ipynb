{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "#graphicalrepresentation of all possible solutions of a decision\n",
    "#we can make decisions easily and quickly\n",
    "# there are splitting(dividing root node(if true else false)) and preuning(removing unwanted branches)in decision tree\n",
    "#example for this decision tree is planning for a trip\n",
    "# splitting\n",
    "# ----------\n",
    "# when splitting is done based on some conditions they are:\n",
    "# a.gini index -> measure of impurity(without impurity-100% decision,with noice or impurity-50% decisin)\n",
    "# b.information game-> decrease in entropy after a dataset is splitted on the basis of an attribute.\n",
    "# c.reduction in varience-> Lower varience will be selected for contineous target.\n",
    "# d.entropy->measure of impurity\n",
    "# gini index and entropy both are measure of impurity but differ in formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree:\n",
    "\n",
    "# data set has 4 attributes they are \n",
    "\n",
    "# company name | job title | degree | salary > 100k\n",
    "\n",
    "# now extract inputs from the data set they are |company name | job title | degree| \n",
    "\n",
    "# then extract outputs from the data set that is salary \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5. ,  3. , 15. ,  7. , 20. ,  2. , 12. ,  4. ,  1. , 10. , 18. ,\n",
       "        6. , 14. , 16. ,  0. , 22. , 19. ,  9. , 13. , 11. , 25. , 21. ,\n",
       "        8. , 17. , 23. , 24. ,  0.5,  1.5,  nan])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import LableEncoder \n",
    "\n",
    "# ds=pd.read_csv(r\"C:\\Users\\91701\\Downloads\\archive (2)\\Salary Data.csv\")\n",
    "# inputs=companyname,degree,job title\n",
    "# outputs=salary > 100k\n",
    "\n",
    "#inputs=ds.iloc[:,:3]\n",
    "#outputs=ds.iloc[:,3:]\n",
    "\n",
    "# l_company=LableEncoder()\n",
    "# l_job=LableEncoder()\n",
    "# l_degree=LableEncoder()\n",
    "\n",
    "#this LableEncoder() is a method to replace the string values with the some other values.\n",
    "#after that add all the attributes to the dataset using the following\n",
    "\n",
    "#inputs['company_n']=l_company.fit_transform(inputs['company'])\n",
    "#inputs['job_n']=l_job.fit_transform(inputs['job'])\n",
    "#inputs['degree_n']=l_degree.fit_transform(inputs['degree'])\n",
    "\n",
    "# the above 3 lines of code will create 3 extra colums in the \n",
    "# dataset and has the numerical values which are replaced with string values\n",
    "\n",
    "# now these updated colums (company_n,job_n,degree_n) are extracted\n",
    "# attributes inside the updated inputs dataset are\n",
    "#company name | job title | degree | l_company | l_job | l_degree |\n",
    "# in the above updated data set we want only 4 to 6 columns so we are slicing colums\n",
    "\n",
    "# updated=ds.iloc[:,3:6]\n",
    "\n",
    "#Now we acquired inputs and the outpus \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TRAINING AND TESTING THE DATA\n",
    "# ----------------------------------\n",
    "\n",
    "# next step that is training and testing\n",
    "# #By importing train_test_split from sklearn.model_selection\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train,x_test,y_train,y_test=train_test_split(updated,outputs,train_size=0.75)\n",
    "\n",
    "#in the above line of code train_size will decide how much of data is assigned for training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE IMPORT CLASSIFIER\n",
    "# --------------------------------\n",
    "\n",
    "# from sklearn import DecisionTreeClassifier\n",
    "\n",
    "#1.create a model\n",
    "# model=DecisionTreeClassifier()\n",
    "#we can pass the arguments inside the ()\n",
    "# like model=DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "#2.fit the data into the model\n",
    "# model.fit(x_train,y_train)\n",
    "\n",
    "#3.predict the values using predict function and pass the data to be tested\n",
    "# model.predict(xtest)\n",
    "\n",
    "#now the values are predicted if we want to know the score ie.,how muck accuratly the model is predicting\n",
    "\n",
    "\n",
    "#4.to know the accuracy of the prediction we will use .score()\n",
    "# model.score(x_test,y_test)\n",
    "#it will compare the predicted value and the actual value and give score\n",
    "# if op for the score is 0.5 the the model is 50% predictable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SEE THE DECISION TREE\n",
    "# ---------------------------\n",
    "#IMPORT SKLEARN IMPORT TREE\n",
    "#tree.plot_tree(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
