a.Support Vector Machine(SVM)
=============================
it can be used for regression as well as classification 

one hyperplain(straight line)or decision boundary is used to categorize 2 or more values in the graph

line below the hyperplane are classified as minus(one class) and line above values are classified as plus(another class)




*linear:screen shot(diagram):
	straight line classification
*non-linear:screen shot(diagram):
	have curve line classification
		
*kernal function:
		transforms lower dimentional space(2D) into higher dimentional space(3D).

In 3d space hyperplane is also in 3d.
 
# here we are going to take same iris data set as example

import pandas as pd
from sklearn.model_Selection import train_test_split
from sklearn.svm import SVC
(#support vector classifier,SVR=support vector regression) 

data=pd.read_csv("path.csv")

#first we need to check wether the presence of any null values.

data["species"].unique()
data["species"].replace({"setosa":"1","versicolor":"2","virginica":"3"},inplace=True)
x=data.iloc(:,1:5)
y=data.ilock(:,5:)
x_train,x_test,y_train,y_test(x,y,train_size=0.8)

model=SVC()
model.predict(xtest)
to check wether the pridicted is accurate or not
model.score(x_test,y_test)
op:
0.933333 
(93% accuracy)
op will different when different data sets are used or in different machines

